{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "acGT5rIeSeGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importa/Instala y Obertura\n",
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfcNVJYbSnYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (Nada) Importa y Puente\n",
        "import torch\n",
        "from transformers import *\n",
        "\n",
        "# Estructura en tuplas para los modelos, con su tokenizer y sus preentrenados \n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "#(BartModel, BartTokenizer, 'bart-large-mnli') Tupla Bart\n",
        "#(TFFlaubertWithLMHeadModel, FlaubertTokenizer, 'flaubert-base-cased') Tupla Flaubert TensorFlow\n",
        "#(TransfoXLLMHeadModel,  TransfoXLTokenizer,  'transfo-xl-wt103') Tupla TXL\n",
        "#(FlaubertWithLMHeadModel, FlaubertTokenizer, 'flaubert-base-cased') Tupla Flaubert\n",
        "#(GPT2DoubleHeadsModel, GPT2Tokenizer , 'gpt2-medium') Tupla GTP2\n",
        "MODELS = [(GPT2LMHeadModel, GPT2Tokenizer , 'gpt2-large')\n",
        "         ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWQMw7LfSnWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inicia las estructuras en nuevos arreglos y Verso\n",
        "tokenizer=[]\n",
        "model = []\n",
        "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
        "    print(model_class) # Pa' saber en cual va\n",
        "    # Carga el preentrenado con el modelo/tokenizer\n",
        "    tok = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "    tokenizer.append(tok)\n",
        "    mod = model_class.from_pretrained(pretrained_weights, pad_token_id=tokenizer[-1].eos_token_id)\n",
        "    model.append(mod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khWQCORsSnU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Codifica textos para cada estructura, almacena en un arreglo y Coro\n",
        "# (esto se debe mejorar para que sea recursivo, eso lo hare(mos)... eventualmente)\n",
        "OUTPUTS = []\n",
        "INPUT = \"str(input())\"\n",
        "for i in range(len(MODELS)):\n",
        "    input_ids = tokenizer[i].encode(INPUT, add_space_before_punct_symbol=True, return_tensors='pt')\n",
        "    OUTPUTS.append(model[i].generate(input_ids, max_length=2*len(INPUT)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO95KHLGT9C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imprime y Fade Out\n",
        "for i in range(len(MODELS)):\n",
        "  print(\"Modelo:\", i)\n",
        "  print(tokenizer[i].decode(OUTPUTS[i][0], skip_special_tokens=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PfD42QST9A3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSV00sP8T87D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm625hqKT83a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
